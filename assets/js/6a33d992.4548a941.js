"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[851],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>d});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},b=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(a),b=o,d=m["".concat(s,".").concat(b)]||m[b]||u[b]||r;return a?n.createElement(d,i(i({ref:t},c),{},{components:a})):n.createElement(d,i({ref:t},c))}));function d(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=b;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}b.displayName="MDXCreateElement"},2021:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var n=a(7462),o=(a(7294),a(3905));const r={sidebar_position:3},i="Jobs",l={unversionedId:"guide-to-dynamic-builds/jobs",id:"guide-to-dynamic-builds/jobs",title:"Jobs",description:"A workflow handler function is responsible for submitting Jobs to be run as part of the build. Each job",source:"@site/docs/guide-to-dynamic-builds/jobs.md",sourceDirName:"guide-to-dynamic-builds",slug:"/guide-to-dynamic-builds/jobs",permalink:"/docs/guide-to-dynamic-builds/jobs",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Workflows",permalink:"/docs/guide-to-dynamic-builds/workflows"},next:{title:"Steps",permalink:"/docs/guide-to-dynamic-builds/steps"}},s={},p=[{value:"Submitting a Job",id:"submitting-a-job",level:2},{value:"Job Definitions",id:"job-definitions",level:2},{value:"Job Callbacks",id:"job-callbacks",level:2},{value:"Artifacts",id:"artifacts",level:2},{value:"Job Dependencies",id:"job-dependencies",level:2},{value:"Docker Configuration",id:"docker-configuration",level:2},{value:"Environment Variables",id:"environment-variables",level:2},{value:"Secrets",id:"secrets",level:2}],c={toc:p},m="wrapper";function u(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"jobs"},"Jobs"),(0,o.kt)("p",null,"A workflow handler function is responsible for submitting ",(0,o.kt)("em",{parentName:"p"},"Jobs")," to be run as part of the build. Each job\ncontains one or more ",(0,o.kt)("em",{parentName:"p"},"Steps"),"."),(0,o.kt)("p",null,"All Steps within a Job are run within the same environment and so steps can share files or other state. Each job\nruns within its own separate environment and should not expect files from other jobs to be available; instead it\nshould declare ",(0,o.kt)("a",{parentName:"p",href:"jobs#job-dependencies"},"Artifact Dependencies")," to make files from other jobs available."),(0,o.kt)("h2",{id:"submitting-a-job"},"Submitting a Job"),(0,o.kt)("p",null,"A new Job is added to a workflow by calling ",(0,o.kt)("inlineCode",{parentName:"p"},"NewJob()")," to create a ",(0,o.kt)("em",{parentName:"p"},"Job Definition"),", then calling the workflow Job()\nmethod to add the definition to a list of jobs ready to be submitted to the server. After the workflow\nfunction returns, any outstanding jobs will be submitted. Properties are set on the Job Definition by\ncalling methods on the object."),(0,o.kt)("p",null,"Here's a complete example of a Workflow Handler that submits a Job, written in Go:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'func handler(w *bb.Workflow) error {\n    w.Job(bb.NewJob().\n        Name("test-job").\n        Step(bb.NewStep().\n            Name("test-job-step").\n            Commands("echo This is the test job..."), \n    ))\n    return nil\n}\n')),(0,o.kt)("p",null,"To submit jobs immediately instead of waiting until the workflow handler returns, call Submit(), or MustSubmit() if you don't want to deal with errors:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},"func (w *Workflow) Submit(waitForCallbacks ...bool) ([]client.JobGraph, error)\nfunc (w *Workflow) MustSubmit(waitForCallbacks ...bool) []client.JobGraph\n")),(0,o.kt)("p",null,"Submit() will submit all new jobs to the server and return details for the newly created jobs. If\nwaitForCallbacks is true, or not specified, Submit() will wait until all outstanding callbacks have been called\nbefore returning. MustSubmit() is the same but will exit the program with status 1 on error, causing the build to fail."),(0,o.kt)("h2",{id:"job-definitions"},"Job Definitions"),(0,o.kt)("p",null,"The following methods are available to set properties on a Job; additional methods are described in later\nsections:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Name")," (mandatory): a name to use when referencing the job.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Desc")," (optional): a human-readable description for the job.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Step")," (mandatory): each ",(0,o.kt)("em",{parentName:"p"},"Step")," is added to the Job by calling NewStep() to create a ",(0,o.kt)("em",{parentName:"p"},"Step Definition"),",\nthen calling the Job's Step() method to add the step. See ",(0,o.kt)("a",{parentName:"p",href:"steps"},"Steps")," for details and examples.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"StepExecution")," (optional): specifies whether the Steps in this Job should be run sequentially (the default)\nor in parallel. Possible values are ",(0,o.kt)("inlineCode",{parentName:"p"},"StepExecutionSequential")," or  ",(0,o.kt)("inlineCode",{parentName:"p"},"StepExecutionParallel"),".")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Fingerprint")," (optional): specifies a way to calculate a ",(0,o.kt)("em",{parentName:"p"},"fingerprint")," for inputs to the Job, allowing\nexecution to be skipped if a previous build already ran the Job with the same inputs, and therefore\nalready produced the required artifacts. See ",(0,o.kt)("a",{parentName:"p",href:"fingerprints"},"Fingerprinting")," for details and examples.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"RunsOn")," (optional): a set of labels constraining which types of runner the job can run on. Only runners\nwhich have all of these labels will be eligible to run this Job. Not relevant when builds are run using\nthe ",(0,o.kt)("em",{parentName:"p"},"bb")," command line tool.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Service")," (optional): Jobs can make use of services such as databases by calling NewService() to create\na ",(0,o.kt)("em",{parentName:"p"},"Service Definition"),", then calling the Job's Service() method to add the service.\nSee ",(0,o.kt)("a",{parentName:"p",href:"services"},"Services")," for details and examples."))),(0,o.kt)("h2",{id:"job-callbacks"},"Job Callbacks"),(0,o.kt)("p",null,"To take advantage of the dynamic nature of builds, a ",(0,o.kt)("em",{parentName:"p"},"Job Callback")," function can be called after\na job has succeeded, failed, or the each time job's status changes. Callbacks are often used to submit\nnew jobs to a workflow after previous jobs have finished, based on the results or artifacts produced by\nthe previous job."),(0,o.kt)("p",null,"The callback function takes a single ",(0,o.kt)("em",{parentName:"p"},"event")," parameter which will contain the Job's new status; other information\n(e.g. artifacts) can be discovered and read from within the callback using the Workflow object."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},"type JobCallback func(event *JobStatusChangedEvent)\n")),(0,o.kt)("p",null,"As with workflow handler functions, after the callback function returns any outstanding jobs will be submitted.\nThe workflow object's Submit() or MustSubmit() functions can also be used in a callback to submit new jobs\nimmediately. Note that the workflow function will often have returned before the callback is called, having finished\nsubmitting the initial set of Jobs to run."),(0,o.kt)("p",null,"The following Job methods are available to define callbacks. Each specifies a function to be called:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"OnCompletion")," (optional): call when the Job is completed (succeeded, failed or cancelled).")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"OnSuccess")," (optional): call when the Job succeeds. Not called on error.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"OnFailure")," (optional): call when the Job fails.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"OnStatusChanged")," (optional): call each time the status of the Job changes."))),(0,o.kt)("p",null,"Here's an example of the use of callbacks in Go:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    w.Job(bb.NewJob().\n        Name("test-callbacks-job").\n        Step(bb.NewStep().Name("step-1").Commands("echo \'Test callbacks job running\'").\n        OnSuccess(func(event *bb.JobStatusChangedEvent) {\n            bb.Log(bb.LogLevelInfo, "Job is finished; new jobs could be created here")\n        }).\n        OnFailure(func(event *bb.JobStatusChangedEvent) {\n            bb.Log(bb.LogLevelInfo, "Job failed")\n        }))\n')),(0,o.kt)("h2",{id:"artifacts"},"Artifacts"),(0,o.kt)("p",null,"An ",(0,o.kt)("em",{parentName:"p"},"Artifact")," is a set of files produced by the Job that form part of the output of the build. When builds are run on\na server, artifact files are stored after the build is completed. When a build is run via the ",(0,o.kt)("em",{parentName:"p"},"bb")," command line\ntool, artifact files remain on the local machine after the build is run."),(0,o.kt)("p",null,"The following Job method is used to define artifacts:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Artifact")," (optional): call NewArtifact() to create an ",(0,o.kt)("em",{parentName:"li"},"Artifact Definition"),", then call the\nJob's Artifact() method to add the artifact. The Artifact() method can be called multiple times to define\nmore than one artifact.")),(0,o.kt)("p",null,"The following methods are available to set properties on an Artifact Definition:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Name")," (mandatory): each artifact must have a name, unique within the build. Names must be identifiers that\ndo not contain spaces.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Paths")," (mandatory): specifies one or more strings, each defining a path that matches files that should be\nincluded in the artifact. Paths are relative to the checked-out source working directory.\nWildcards (*) can be used to pattern-match parts of a path."))),(0,o.kt)("p",null,"Here's an example of a Job that defines an Artifact that includes all files in the reports directory (some details\nreplaced with ",(0,o.kt)("inlineCode",{parentName:"p"},"....")," for brevity):"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    w.Job(bb.NewJob().\n        Name("reporting-job").\n        Artifact(bb.NewArtifact().\n            Name("reports").\n            Paths("reports/*")).\n        Step(....))\n')),(0,o.kt)("h2",{id:"job-dependencies"},"Job Dependencies"),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Job dependencies")," can be used to ensure a job doesn't run until after another job completes, and optionally to\nmake available artifacts from another job. If no job dependencies are specified then all submitted jobs\nare eligible to run in parallel."),(0,o.kt)("p",null,"The following Job methods are available to define dependencies:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Depends")," (optional): specifies one or more dependencies as strings, using the YAML\n",(0,o.kt)("a",{parentName:"p",href:"../yaml-guide/jobs#job-dependency-syntax"},"Job Dependency Syntax"),". The specified job can be in a different\nworkflow from the dependent job; this can be used as a more efficient alternative to\n",(0,o.kt)("a",{parentName:"p",href:"workflows#workflow-dependencies"},"Workflow Dependencies"),"."),(0,o.kt)("p",{parentName:"li"},"Here's an example where ",(0,o.kt)("em",{parentName:"p"},"job-2")," depends on ",(0,o.kt)("em",{parentName:"p"},"job-1")," and requires all artifacts from ",(0,o.kt)("em",{parentName:"p"},"job-1")," to be available\n(some details replaced with ",(0,o.kt)("inlineCode",{parentName:"p"},"....")," for brevity):"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    w.Job(bb.NewJob().\n        Name("job-1").\n        Step(....).\n        Artifacts(....))\n    w.Job(bb.NewJob().\n        Name("job-2").\n        Depends("my-workflow.job-1.artifacts").\n        Step(....))\n'))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"DependsOnJobs")," (optional): indicates that the job depends on the specified other jobs, provided as\nreferences to Job objects defined previously.\nThis is a simpler alternative to using dependency strings of the form ",(0,o.kt)("inlineCode",{parentName:"p"},"workflowname.jobname")," (see example below).")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"DependsOnJobArtifacts")," (optional): indicates that the job depends on the specified other jobs, and that\nall artifacts from those jobs should be made available to the dependent job.\nThis is a simpler alternative to using dependency strings of the form ",(0,o.kt)("inlineCode",{parentName:"p"},"workflowname.jobname.artifacts"),". Here's an example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    job1 := bb.NewJob().\n        Name("job-1").\n        Step(....).\n        Artifacts(....)\n    w.Job(job1)\n\n    w.Job(bb.NewJob().\n        Name("job-2").\n        DependsOnJobArtifacts(job1).\n        Step(....))  \n')))),(0,o.kt)("h2",{id:"docker-configuration"},"Docker Configuration"),(0,o.kt)("p",null,"Jobs can run either in a Docker container ('docker' jobs) or natively on the machine where the runner or ",(0,o.kt)("em",{parentName:"p"},"bb"),"\nexecutable is running ('native' or 'exec' jobs)."),(0,o.kt)("p",null,"For Docker jobs, configuration options can be specified on a per-job basis using the following Job method:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Docker")," (optional): call NewDocker() to create a ",(0,o.kt)("em",{parentName:"li"},"Docker Configuration"),", then call the Job's Docker() method\nto configure Docker for the job.")),(0,o.kt)("p",null,"The following methods are available to set properties on an Docker Configuration:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Image")," (mandatory): specifies the name of the Docker image to use when running this Job.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"BasicAuth")," (optional): configures basic auth credentials for the Docker registry, to use when fetching the Docker\nimage to run under. Takes a BasicAuth object to specify the username and password for authentication, using\n",(0,o.kt)("a",{parentName:"p",href:"jobs#secrets"},"Secrets")," to keep passwords secure..")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"AWSAuth")," (optional): configures AWS auth credentials for AWS ECR, to use when fetching the Docker\nimage to run under. Takes an AWSAuth object to specify the details for authentication, using\n",(0,o.kt)("a",{parentName:"p",href:"jobs#secrets"},"Secrets")," to keep IDs and passwords secure.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Shell")," (optional): specifies the shell to use to run commands inside the docker container.\nDefault is '/bin/sh' for Unix-based containers, or 'cmd.exe' for Windows-based containers.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Pull")," (optional): specifies when to pull the Docker image from the Registry. Constants are provided for\nthese options:"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"DockerPullNever"),": never pull the image; it must already exist in the cache")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"DockerPullAlways"),": always pull the image, just before the Job is run each time")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"DockerPullIfNotExists"),": pull the image only if there is no version in the cache")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"DockerPullDefault"),": the default behaviour if no Pull() option specified. This is equivalent to\n",(0,o.kt)("em",{parentName:"p"},"DockerPullAlways")," if the image tag is 'latest', or ",(0,o.kt)("em",{parentName:"p"},"DockerPullIfNotExists")," if the image tag refers\nto a specific version."))))),(0,o.kt)("p",null,"Here's an example of a docker Job with an image and pull strategy defined (some details\nreplaced with ",(0,o.kt)("inlineCode",{parentName:"p"},"....")," for brevity):"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    w.Job(bb.NewJob().\n        Name("a-docker-based-job").\n        Docker(bb.NewDocker().\n            Image("node:18.4.0-alpine").\n            Pull(bb.DockerPullIfNotExists))).\n        Step(....))\n')),(0,o.kt)("h2",{id:"environment-variables"},"Environment Variables"),(0,o.kt)("p",null,"Jobs can be provided information via environment variables. Variables specified in the Job definition apply to\nevery Step within the Job. The values for variables can be provided as literal values, or\n",(0,o.kt)("a",{parentName:"p",href:"jobs#secrets"},"Secrets")," can be used to ensure that the provided information remains secure."),(0,o.kt)("p",null,"Environment variables can be specified using the following Job method:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Env")," (optional): specifies an environment variable that should be passed to commands that run within the Job\nwhen they are executed. The Env() method can be called multiple times to add multiple variables.")),(0,o.kt)("p",null,"The following methods are available to set properties on an environment variable."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Name")," (mandatory): specifies the name of the environment variable to be provided to the Job. This can be\nreferenced from within shell commands with name in UPPER_CASE.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Value"),": specifies a literal value for the environment variable; use this only for values that do not\nneed to be kept secret.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"ValueFromSecret"),": the name of a ",(0,o.kt)("em",{parentName:"p"},"Secret")," used to obtain the value for the\nenvironment variable; the actual value will be fetched at runtime."))),(0,o.kt)("p",null,"(note that either ",(0,o.kt)("em",{parentName:"p"},"Value")," or ",(0,o.kt)("em",{parentName:"p"},"ValueFromSecret")," must be called)"),(0,o.kt)("p",null,"Here's an example of a Job being passed environment variables, with and without secrets:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-go"},'    w.Job(bb.NewJob().\n        Name("my-job").\n        Env(bb.NewEnv().\n            Name("MY_ID").\n            Value("a-literal-value")).\n        Env(bb.NewEnv().\n            Name("AWS_SECRET_ACCESS_KEY").\n            ValueFromSecret("ACCESS_KEY_SECRET_NAME")).\n        Step(bb.NewStep().\n            Name("go-builder").\n            Commands("echo My ID is $MY_ID")))\n')),(0,o.kt)("h2",{id:"secrets"},"Secrets"),(0,o.kt)("p",null,"Secrets provide a mechanism to avoid sensitive information such as passwords or tokens having to be hard coded\ninto the build definition YAML or code. Secrets are used by providing a ",(0,o.kt)("em",{parentName:"p"},"secret name")," instead of a literal value,\nand can be used for ",(0,o.kt)("a",{parentName:"p",href:"jobs#environment-variables"},"Enviroment Variables")," or within\n",(0,o.kt)("a",{parentName:"p",href:"jobs#docker-configuration"},"Docker Configuration")," - see those sections for the syntax."),(0,o.kt)("p",null,"The values for secrets are provided at runtime:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Builds run via the "),"bb",(0,o.kt)("em",{parentName:"p"}," command-line tool"),": secret values are provided via environment variables set when\nbb is run. For each secret there must be a corresponding environment variable with the same name.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Builds run from the BuildBeaver server"),": secret values are set within the Build Configuration via the GUI."))))}u.isMDXComponent=!0}}]);